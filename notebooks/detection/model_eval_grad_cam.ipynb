{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1jkeVJAMULCFIGAAvejpBpqyFfwtajKhM","authorship_tag":"ABX9TyO4n28V6lA9bY9Qi1iCCDWm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2A92rJsLe-Ky"},"outputs":[],"source":["!pip install torchcam"]},{"cell_type":"code","source":["from PIL import Image\n","#import splitfolders\n","\n","import numpy as np \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torchvision.models import mobilenet_v3_large\n","from torch import nn, optim\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZT_A2VtZfRan","executionInfo":{"status":"ok","timestamp":1662658125846,"user_tz":-420,"elapsed":346,"user":{"displayName":"Syair Dafiq","userId":"08105544619256875002"}},"outputId":"b64f563f-cd26-4adc-9ec0-0ebd5a29513d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":215}]},{"cell_type":"code","source":["bs = 64\n","crop_size = 224\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(320),\n","    transforms.CenterCrop(crop_size),\n","    transforms.ToTensor(),\n","])\n","\n","\n","test_set = datasets.ImageFolder(\"/content/drive/MyDrive/belajar python/case study/forest fire/img/val\", transform=test_transform)\n","testloader = DataLoader(test_set, batch_size=bs, shuffle=False)"],"metadata":{"id":"NpdhRg-3gaqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ForestFireRecognition(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.mnet = model = mobilenet_v3_large()\n","        self.mnet.classifier = nn.Sequential(\n","            nn.Hardswish(),\n","            nn.Linear(960,1280),\n","            nn.Hardswish(),\n","            nn.Dropout(0.2),\n","            nn.Linear(1280,2),\n","            nn.LogSoftmax(1)\n","        )\n","    def forward(self,x) :\n","        x = self.mnet(x)\n","        return x\n","\n","    def features(self):\n","        return self.mnet.features"],"metadata":{"id":"cg0nTeZOj6yB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ForestFireRecognition().to(device)\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/belajar python/case study/forest fire/model/mobilenetv3_98.pth\",map_location=torch.device('cpu')))\n","model.to(device)\n","target_layers = [model.features()]"],"metadata":{"id":"9xqB8ESIfi3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itr = iter(testloader)\n","feature,target = next(itr)\n","feature , target = feature.to(device), target.to(device)"],"metadata":{"id":"Y4_hl3iVwDrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.io.image import read_image\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from torchcam.methods import SmoothGradCAMpp,XGradCAM,ScoreCAM,GradCAMpp,LayerCAM\n","\n","cam_extractor = XGradCAM(model,target_layers)\n","\n","list_result = []\n","\n","for i in range(1,feature.shape[0]):\n","    # Preprocess your data and feed it to the model\n","    out = model(feature[i].unsqueeze(0))\n","    # Retrieve the CAM by passing the class index and the model output\n","    activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n","    result = overlay_mask(to_pil_image(feature[i]), to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.8)\n","    list_result.append(result)"],"metadata":{"id":"KFzKIvIEzvWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axes = plt.subplots(5,5,figsize = (24,24))\n","for image, grad, ax in zip(feature,list_result,axes.flatten()):\n","    ax.imshow(grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SHHCt-x8Jo13H6excY6YlOt37lQQ3O36"},"id":"WGnEypNS1yo5","executionInfo":{"status":"ok","timestamp":1662658158113,"user_tz":-420,"elapsed":6000,"user":{"displayName":"Syair Dafiq","userId":"08105544619256875002"}},"outputId":"3c86bc98-1925-4618-8a2a-7f2ed161de3a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["fig,axes = plt.subplots(5,5,figsize = (24,24))\n","for image, grad, ax in zip(feature,list_result,axes.flatten()):\n","    ax.imshow(grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"109SIBJDNTektgxFOXKVtaOLJZGqomLbX"},"id":"I5ZZviQZJ-vB","executionInfo":{"status":"ok","timestamp":1662658353321,"user_tz":-420,"elapsed":5942,"user":{"displayName":"Syair Dafiq","userId":"08105544619256875002"}},"outputId":"f7cedf9c-ba78-424c-de8d-b5835d969160"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}